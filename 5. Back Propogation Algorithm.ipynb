{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d027966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2051f338",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[2,9],[1,5],[3,6]], dtype=float)\n",
    "y = np.array([[92],[86],[89]], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70787e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#amax gathers datasets for normalisation\n",
    "x = x/np.amax(x, axis=0)\n",
    "y = y/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02d51191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86898b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivates_sigmoid(x):\n",
    "    return x*(1-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6547ad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some constant values\n",
    "epoch = 5000 #Loop number\n",
    "lr = 0.1 #learning rate of machine\n",
    "inputlayer_neurons = 2\n",
    "hiddenlayer_neurons = 3\n",
    "outputlayer_neurons = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8df42b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random.uniform random numbers of given size are uniformly distributed (low to high)\n",
    "wh = np.random.uniform(size = (inputlayer_neurons, hiddenlayer_neurons)) #weight of hidden layers\n",
    "bh = np.random.uniform(size = (1, hiddenlayer_neurons)) #bias of hidden layers\n",
    "wout = np.random.uniform(size = (hiddenlayer_neurons, outputlayer_neurons)) #weight of output layers\n",
    "bout = np.random.uniform(size = (1, outputlayer_neurons)) #bias of output layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02bd0d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runs 5000 times\n",
    "for i in range(epoch):\n",
    "    #Forward Propogation starts here\n",
    "    #dot returns dot product of vector\n",
    "    hin = np.dot(x,wh) #hin is hidden input\n",
    "    hin = hin + bh\n",
    "    #Activating hidden layer\n",
    "    hlayer_act = sigmoid(hin)\n",
    "    oin = np.dot(hlayer_act, wout) #hin is outpout input\n",
    "    oin = oin + bout\n",
    "    #Activating output layer\n",
    "    olayer_act = sigmoid(oin)\n",
    "    \n",
    "    \n",
    "    #Backward Propogation starts here\n",
    "    EO = y - olayer_act #EO is error of output layer\n",
    "    outgrad = derivates_sigmoid(olayer_act)\n",
    "    d_out = EO * outgrad\n",
    "    EH = d_out.dot(wout.T) #EH is error of hidden layer & .T is for transpose\n",
    "    hiddengrad = derivates_sigmoid(hlayer_act)\n",
    "    d_hid = EH * hiddengrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1258c8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.7860256 ]\n",
      " [0.77913104]\n",
      " [0.78456899]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\" ,x) \n",
    "print(\"Actual Output: \\n\",y)\n",
    "print(\"Predicted Output: \\n\" ,olayer_act)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
